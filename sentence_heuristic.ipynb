{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\bran_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# Download the word list if not already downloaded\n",
    "nltk.download('words')\n",
    "\n",
    "# Load the English words dataset\n",
    "dictionary = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heuristic function as a baseline model to compare our sentence segmenting model against\n",
    "#dynamic programming implementation using a dictionary of english words to segment sentences\n",
    "\n",
    "def segment_sentence(s):\n",
    "    n = len(s)\n",
    "    dp = [None] * (n + 1)\n",
    "    dp[0] = \"\"\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(i):\n",
    "            word = s[j:i]\n",
    "            if word in dictionary and dp[j] is not None:\n",
    "                dp[i] = (dp[j] + \" \" + word).strip()\n",
    "                break\n",
    "    \n",
    "    return dp[n] if dp[n] else \"No valid segmentation found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different implemtation of segment sentence heuristic using greedy algo\n",
    "def segment_sentence_greedy(s):\n",
    "    segmented = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        for j in range(i + 1, len(s) + 1):\n",
    "            word = s[i:j]\n",
    "            if word in dictionary:\n",
    "                segmented.append(word)\n",
    "                i = j  # Move index forward to the next part of the string\n",
    "                break\n",
    "        else:\n",
    "            # If no valid word is found, move forward by 1 character (bad behavior)\n",
    "            segmented.append(s[i])\n",
    "            i += 1\n",
    "\n",
    "    return \" \".join(segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternate heuristic implementation\n",
    "def segment_sentence_moderate(s):\n",
    "    segmented = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        longest_word = None\n",
    "        longest_end = i + 1\n",
    "\n",
    "        # Look for the longest possible word\n",
    "        for j in range(i + 1, len(s) + 1):\n",
    "            word = s[i:j]\n",
    "            if word in dictionary:\n",
    "                longest_word = word\n",
    "                longest_end = j  # Save position to continue from\n",
    "\n",
    "        # If a valid word was found, use it\n",
    "        if longest_word:\n",
    "            segmented.append(longest_word)\n",
    "            i = longest_end  # Move to the next part of the string\n",
    "        else:\n",
    "            # If no word is found, take the single letter (bad behavior)\n",
    "            segmented.append(s[i])\n",
    "            i += 1\n",
    "\n",
    "    return \" \".join(segmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another alt heuristic\n",
    "def segment_sentence_mid_bad(s):\n",
    "    segmented = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        found = False\n",
    "\n",
    "        # Look for the first word it finds, but skip words shorter than 3 letters if possible\n",
    "        for j in range(i + 1, len(s) + 1):\n",
    "            word = s[i:j]\n",
    "            if word in dictionary and (len(word) > 2 or j == len(s)):  # Avoid tiny words unless no choice\n",
    "                segmented.append(word)\n",
    "                i = j  # Move forward\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        # If no valid word found, take the first 2 characters (slightly better than 1)\n",
    "        if not found:\n",
    "            segmented.append(s[i:i+2])  # Grab 2 characters at a time (worse behavior)\n",
    "            i += 2\n",
    "\n",
    "    return \" \".join(segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bran_\\AppData\\Local\\Temp\\ipykernel_13676\\3294508708.py:8: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random_words = random.sample(dictionary, sentence_length)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "#create random english sentences\n",
    "import random\n",
    "\n",
    "numSentences = 100\n",
    "sentences = []\n",
    "for i in range(numSentences):\n",
    "    sentence_length = random.randint(2, 20)\n",
    "    random_words = random.sample(dictionary, sentence_length)\n",
    "\n",
    "    sentence = \" \".join(random_words)\n",
    "    concat_sentence = \"\".join(random_words)\n",
    "\n",
    "    sentences.append([sentence, concat_sentence])\n",
    "\n",
    "\n",
    "#after this, sentences holds tuples of strings (sentence, concat_sentence)\n",
    "#ex. if sentence is \"hello there\" concat_sentence is \"hellothere\"\n",
    "#will use this to test accuracy of our baseline heuristic segment_sentence\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(numSentences):\n",
    "    segmented_sentence = segment_sentence_moderate(sentences[i][1])\n",
    "    if segmented_sentence == sentences[i][0]:\n",
    "        accuracy = accuracy + 1\n",
    "        #print(segmented_sentence + \":::::\" + sentences[i][0])\n",
    "\n",
    "accuracy = float(accuracy / numSentences)\n",
    "\n",
    "print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
